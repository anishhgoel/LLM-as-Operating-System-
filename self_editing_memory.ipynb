{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. If you'd like to share it or ask anything else, feel free!\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "        {\"role\" : \"user\" , \"content\" : \"What is my name\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDING Memory to the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\" : \"Name : Alex\"}\n",
    "system_prompt = \"You are a chatbot. You have a section of context called [MEMORY] that contains information relavant to your conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Alex.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt + \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        {\"role\" : \"user\" , \"content\" : \"What is my name\"},\n",
    "    ]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying memory with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a memory editing tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\" : \"\", \"agent\" : \"\"}\n",
    "\n",
    "def core_memory_save(section: str, memory: str):\n",
    "    agent_memory[section] += '\\n'\n",
    "    agent_memory[section] += memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': '', 'agent': ''}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_save(\"human\", \"My name is Brandon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': '\\nMy name is Brandon', 'agent': ''}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_description = \"Save important information about you, the agent or the human you are chatting with\"\n",
    "\n",
    "core_memory_save_properties = {\n",
    "    \"section\" : {\n",
    "        \"type\" : \"string\",\n",
    "        \"enum\" : [\"human\", \"agent\"],\n",
    "        \"description\" : \"Must be either 'human'(to save information about human) or 'agent' (to save information about yourself)\",\n",
    "    },\n",
    "    \"memory\":{\n",
    "        \"type\" : \"string\",\n",
    "        \"description\" : \"Memory to save in the section\"\n",
    "    }\n",
    "}\n",
    "\n",
    "core_memory_save_metadata = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\": {\n",
    "        \"name\" : \"core_memory_save\",\n",
    "        \"description\" : core_memory_description,\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" : core_memory_save_properties,\n",
    "            \"required\" : [\"section\", \"memory\"]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kkkFB0O2XYe6oRnjXHWOh2Za', function=Function(arguments='{\"section\":\"human\",\"memory\":\"Name is Jiake\"}', name='core_memory_save'), type='function')]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory = {\"human\" : \"\"}\n",
    "system_prompt = \"You are a chatbot. You have a section of context called [MEMORY] that contains informationrelevant to your conversation.\"\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "        {\"role\" : \"system\", \"content\" : \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        {\"role\" : \"user\", \"content\" : \"My name is Jiake\"},\n",
    "    ],\n",
    "    tools = [core_memory_save_metadata]\n",
    ")\n",
    "\n",
    "response =  chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': ''}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'human', 'memory': 'Name is Jiake'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_save(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': '\\nName is Jiake'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the next agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your name is Jiake.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "        {\"role\": \"system\", \"content\" : \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        {\"role\" : \"user\", \"content\" : \"what is my name ?\"},\n",
    "    ],\n",
    "    tools = [core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the agentic loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\" : \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_os = system_prompt + \"You must either call a tool (core_memory_save) or write a response to the user.\" \\\n",
    "+ \"Do not take the same action multiple times!\" + \"When you learn new information, make sure to always call the core_memory_save tool.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_step(user_message):\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt_os},\n",
    "        #memory\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "        },\n",
    "    ]\n",
    "    messages.append({\"role\" : \"user\", \"content\" : user_message})\n",
    "    #agentic loop\n",
    "    while True:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            tools = [core_memory_save_metadata],\n",
    "        )\n",
    "        response = chat_completion.choices[0]\n",
    "\n",
    "        messages.append(response.message)\n",
    "        #if not calling a tool(responsing to the user), return\n",
    "        if not response.message.tool_calls:\n",
    "            return response.message.content\n",
    "\n",
    "        #if calling a tool, execute the tool\n",
    "        else:\n",
    "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
    "\n",
    "            arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "\n",
    "            core_memory_save(**arguments)\n",
    "            messages.append({\n",
    "                \"role\" : \"tool\",\n",
    "                \"tool_call_id\" : response.message.tool_calls[0].id,\n",
    "                \"name\" : \"core_memory_save\",\n",
    "                \"content\" : f\"Updated_memory: {json.dumps(agent_memory)}\"\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL CALL: Function(arguments='{\"section\":\"human\",\"memory\":\"Anish\\'s favorite animal is Dog.\"}', name='core_memory_save')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Got it! Your favorite animal is a dog.'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_step(\"My favorite color is Blue\")\n",
    "agent_step(\"My favorite cuisine is Italian\")\n",
    "agent_step(\"My favorite animal is Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your favorite animal is a dog!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "        {\"role\": \"system\", \"content\" : \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        {\"role\" : \"user\", \"content\" : \"what is my nfavorite animal ?\"},\n",
    "    ],\n",
    "    tools = [core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
